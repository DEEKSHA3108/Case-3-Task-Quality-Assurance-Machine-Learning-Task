# Case-3-Task-Quality-Assurance-Machine-Learning-Task
Call Transcript Classification using Machine Learning
ğŸ“Œ Project Overview
This project applies Machine Learning to classify call transcripts into:

Category 6: Introduction Calls
Category 7: Final Loan Details & Next Steps
Goals
âœ” Improve recall from 2% (existing heuristic method)
âœ” Maintain high accuracy (~80% or more)
âœ” Automate sales call classification

ğŸ“Š Dataset & Preprocessing
Dataset:

400 labeled examples
2000 unlabeled examples
Preprocessing Steps:

Dictionary String Conversion â†’ Converts dictionary-like text into structured format
Feature Engineering:
Low Cardinality Features â†’ One-Hot Encoding
High Cardinality Features â†’ Embedding-based numerical mapping
Label Encoding â†’ Converts categorical target labels to numerical values
Data Splitting â†’ Training, Validation, and Testing sets
ğŸ›  Machine Learning Models Used
Supervised Learning Models
Random Forest â†’ Best Performer (96.25% Accuracy, 96.25% Recall, 95.60% F1-score)
Gradient Boosting â†’ (95% Accuracy, 95% Recall, 95.48% F1-score)
Decision Tree â†’ (92.5% Accuracy, 92.5% Recall, 93.49% F1-score)
âœ… Key Takeaway: Random Forest outperformed all other models, correctly classifying 98.75% of the labeled data.

Semi-Supervised Learning Model
Autoencoder for Feature Extraction
XGBoost Classifier with Pseudo-Labelling
âœ… Performance:

Category 6 â†’ 91.5% Accuracy, 100% Recall, 87% F1-score
Category 7 â†’ 91.5% Accuracy, 97% Recall, 97% F1-score
ğŸ“Œ Observation: The semi-supervised model performed well, but struggled with Category 6 due to limited labeled data.

ğŸš€ Key Findings & Observations
âœ… Strengths:
âœ” Significant improvement over heuristic methods
âœ” High recall & F1-score in both categories
âœ” Regularization techniques (Gaussian noise, Early Stopping, Dropout) reduced overfitting

âš  Limitations:
âŒ Small labeled dataset (400 examples) â†’ Risk of overfitting
âŒ Autoencoder complexity â†’ Did not add significant improvement

ğŸ† Conclusion
Supervised models (especially Random Forest) outperformed Semi-Supervised models
Substantial accuracy & recall improvement over previous heuristic-based classification
Future improvements could involve increasing labeled data and enhancing feature extraction techniques

Semi-supervised model performed well but struggled with Category 6 due to limited labeled data.
ğŸš€ Key Findings & Observations
âœ… Strengths:
âœ” Significant improvement over heuristic methods
âœ” High recall & F1-score in both categories
âœ” Regularization techniques (Gaussian noise, Early Stopping, Dropout) reduced overfitting

âš  Limitations:
âŒ Small labeled dataset (400 examples) â†’ Risk of overfitting
âŒ Autoencoder complexity â†’ Did not add significant improvement
